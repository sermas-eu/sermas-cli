The toolkit is at the core of the SERMAS modular architecture and offers a set of features developers can use when creating new applications. The toolkit setup includes the allocation of resources like computing, GPUs, storage, and database systems. 
XR Developers can login to the Toolkit Developer Console, create an agent, select modules (e.g. integrated dialogue capabilities, detection mechanisms for people and objects), and customise everything to be applied in different contexts. 
The toolkit will be exploited as a sort of platform that supports innovators in developing socially acceptable XR systems by simplifying the design, development, deployment, and management phases. 
The toolkit offers an API to interact with the available modules. Users will be able to register and create their applications and benefit from the modules developed within SERMAS and the open call(s). We plan to provide a CLI (command line interface) to ease the interaction with the APIs and provide easy-to-use documentation to interact with the SERMAS Toolkit. 
The toolkit is an integrated set of features that allows the creation of agents (virtual or robotics) which should be able to show behaviours and reactions that are accepted by the users as it was a real person. In other words, the agents should be able to automatically detect the presence of a person, act gestures such as greetings and start interacting via face-to-face communication to establish a friendly interaction. Being able to infer the emotional state of the user, the agents can adapt their responses and behaviours, accordingly, providing a more personalised and empathetic experience.  